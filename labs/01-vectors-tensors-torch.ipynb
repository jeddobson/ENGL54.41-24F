{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Critical AI</center>\n",
    "<center>ENGL 54.41</center>\n",
    "<center>Dartmouth College</center>\n",
    "<center>Fall 2024</center>\n",
    "<pre>Created: 08/23/2019; Revised: 09/18/2024</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is Jupyter code cell. This line is a comment; \n",
    "# comments are not executed by the interpreter.\n",
    " \n",
    "# Here we are assigning a variable 'course_title' the value of 'Critical AI',\n",
    "# this will automatically make 'course_title' a String.\n",
    "course_title = 'Critical AI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the type assigned, we can use the type() function:\n",
    "type(course_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see or display the value of a String (especially a short one), we can use the print() function:\n",
    "print(course_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Datatypes: Strings \n",
    " \n",
    "You can query the Python interpreter for documentation on what can be done with a \n",
    "particular datatype with the help() function. Just like you can learn what can be \n",
    "done with the print() function by executing help(print),you can ask for some basic \n",
    "documentation on the datatype with help(str) which gives us help for the class Str or String. \n",
    "Try that below by creating a new cell and executing that function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strings enable us to store and manipulate data, especially text-based data.\n",
    "# They are sequences of characters and they are perfect for the manipulation of text.\n",
    "# We can easily access individual characters by indexing the string by character position:\n",
    "\n",
    "print(course_title[0])\n",
    "print(course_title[1])\n",
    "print(course_title[2])\n",
    "print(course_title[3])\n",
    "print(course_title[4])\n",
    "print(course_title[5])\n",
    "print(course_title[6])\n",
    "print(course_title[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But that was a silly way of obtaining those characters:\n",
    "print(course_title[:8])\n",
    "\n",
    "# Here we've just exposed something potentially confusing: Strings-as-sequences begin with \n",
    "# the index of 0, so the first character is the zero-eth element but some \n",
    "# methods are going to ask for a specific number of characters--so we want\n",
    "# the first eight characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try It: Print the second word of the course title\n",
    "In the cell below, print just the second word of the course title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More String Methods\n",
    "There is a *lot* more that you can do with strings. Review the help(str) documentation for a full list and examples. We'll just quickly look at few examples now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are so many methods that we can perform on strings. \n",
    "\n",
    "# Here's a longer string:\n",
    "sentence = \"\"\"To care for poetry in this way does not make one a poet, but it \n",
    "does make one feel blessedly rich, and quite indifferent to many things which\n",
    "are usually looked upon as desirable possessions\"\"\"\n",
    "\n",
    "# We can count the occurance of items.\n",
    "sentence.count(\"one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can change the case of strings.\n",
    "sentence.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try It: Make it all lowercase\n",
    "In the cell below, display this variable in lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can remove those newline characters represented as '\\n'\n",
    "sentence.replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that these strings are immutable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence[0] = \"Z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can, however, reassign a value to string replacing its present content\n",
    "sentence = sentence.replace('\\n',' ')\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Datatypes: Lists \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists store values. They can combine different datatypes. They can even contain other lists.\n",
    "# Lists can be created easily enough and are trivially modified.\n",
    "\n",
    "# Here is a simple list of numbers\n",
    "example_list = [1,2,3,4,5]\n",
    "\n",
    "# You can also do that with range()\n",
    "example_list = list(range(1,6))\n",
    "\n",
    "example_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But what about using strings in lists?\n",
    "example_list = [\"one\",\"two\",\"three\",\"four\",\"five\",\"six\"]\n",
    "\n",
    "# display the first item in our list\n",
    "example_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try It: Add items to a list\n",
    "Add another word to the list (example_list) with the append method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the result:\n",
    "example_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration is simple, but list comprehension--that's cool!\n",
    "[w.upper() for w in example_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This did not actually modify the list. You could overwrite the \n",
    "# entire list with variable assignment or modify item by item.\n",
    "\n",
    "for i, w in enumerate([w.upper() for w in example_list]):\n",
    "    example_list[i] = w\n",
    "\n",
    "# The enumerate() function gives us both a list and the indices for that list--it's really handy.\n",
    "example_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Vectors, Matrices, and Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python supports a very large number of libraries that can be loaded\n",
    "# or imported as needed. We only import the libraries that we need in \n",
    "# order to reduce the memory requirements and (possibly) prevent \n",
    "# collisions in the namespace used by various functions.\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch (torch) is a very popular library for building neural networks and \n",
    "# for deep learning. https://pytorch.org/\n",
    "# \n",
    "# It is the industry standard for working with the kinds of AI & ML technologies\n",
    "# that we will be studying this year. \n",
    "# \n",
    "# It introduces a new datatype called a tensor. Tensors are similar to the\n",
    "# arrays and matrices used by NumPy (numpy) but are designed to run on faster\n",
    "# processing devices called GPU (graphics processing units) that we will be\n",
    "# hopefully using later this term. They also can keep a record, some history,\n",
    "# of the transformations that created them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pytorch Tensor Types](../img/pytorch-tensor-types.png)\n",
    "\n",
    "Pytorch Tensor Types from Eli Stevens et al. *Deep Learning with Pytorch* (Manning, 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectors and Vectorization\n",
    "\n",
    "The sociologist Adrian Mackenzie writes in [*Machine Learners: Archaeology of a Data Practice*](https://mitpress.mit.edu/author/adrian-mackenzie-8915/) (MIT Press, 2017) of the function of vectorization as a remapping of space:\n",
    "\n",
    "\"Machine learning locates data practice in an expanding epistemic space. The expansion\n",
    "derives, I will suggest, from a specific operational diagram that maps data into a vector\n",
    "space. It vectorizes data according to axes, coordinates, and scales. Machine learners, in\n",
    "turn, inhabit a vectorized space, and their operations vectorize data...Often data are represented as a homogenous set of numbers or a continuous flowing stream. We need, however, to archaeologically examine some of the transformations that allow different shapes and densities of data, whether in the form of numbers,\n",
    "words, or images, to become machine learnable. Data in their local complexes space\n",
    "out in many different density shapes, depending on how the changes, signals, propensities,\n",
    "and norms have been generated or configured.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A vector is typically thought of as a single dimension list of values, not unlike a list.\n",
    "#\n",
    "# This variable is list of floating point numbers. What's a floating point number? It's a numerical value \n",
    "# with greater precision than a integer (i.e., the int 4 vs. the float 4.3). \n",
    "vec = [4.3, 3.0, 1.1, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we try perform an operation on the list (on every element of the list) we will \n",
    "# most likely not get the result we want:\n",
    "vec * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting this list to an array (and treating as a vector) enables us to apply a \n",
    "# transformation to the entire vector at once:\n",
    "vec = np.array(vec)\n",
    "vec * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do other fun stuff with this vector. For example, here are some basic \n",
    "# summary statistics:\n",
    "vec.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now display all these at once:\n",
    "vec_mean = vec.mean()\n",
    "vec_min = vec.min()\n",
    "vec_max = vec.max()\n",
    "print(f'mean: {vec_mean}, min: {vec_min}, max: {vec_max}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to now use Pytorch tensors rather than numpy arrays. This is because\n",
    "# this datatype is especially good for the sort of work we are going to do in\n",
    "# Critical AI.\n",
    "\n",
    "vec1 = torch.tensor([4.3,3.0,1.1,0.1])\n",
    "vec2 = torch.tensor([6.3,2.8,5.1,1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say that these are representations of two kinds of flowers (because they are).\n",
    "# The values, let's call them features, are measures of the length and width of two \n",
    "# types of flower appendages (sepal and petal). \n",
    "#\n",
    "# How might we answer the question of how similar are these two flowers?\n",
    "#\n",
    "# One way might be to find the difference across all four feature dimensions. We can\n",
    "# take the absolute value of that difference to get a sense of how similar these two\n",
    "# samples are to each other:\n",
    "torch.abs(vec1 - vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also combine these 1D vectors into a 2D (tensor) matrix:\n",
    "matrix = torch.vstack([vec1,vec2])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell us about this matrix--what is it shape? How many rows and columns do we have?\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display mean values across all four feature dimensions of the \n",
    "matrix.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display standard deviation values across all four feature dimensions of the \n",
    "matrix.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Better Way: The Distance Matrix\n",
    "\n",
    "Reconceptualizing our data as features in a standardize space (via vectorization) allows us to measure distances between points, where each point is a multidimensional value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean distance is a measurement of a straight line between two points\n",
    "# https://en.wikipedia.org/wiki/Euclidean_distance\n",
    "from sklearn.metrics import euclidean_distances\n",
    "\n",
    "# Cosine similarity is a measurement of the angle between two vectors\n",
    "# https://en.wikipedia.org/wiki/Cosine_similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will look a bit funny, but here we are measuring the distance\n",
    "# on a straight line between 4 and 10. We are seeing these distances\n",
    "# as pairs. The first row displays the distance betwen 4 and 4\n",
    "# and then 4 and 10. The second begins with the later and then the former.\n",
    "#\n",
    "# This is a know as the distance matrix. As we add values, we can compare \n",
    "# distances among all the rows and columns. The top and bottom triangle \n",
    "# separated by the  diagonal measuring the distance between each item to \n",
    "# itself, thus all zeros\n",
    "#\n",
    "euclidean_distances([[4],[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the distance matrix for our separate vectors:\n",
    "euclidean_distances([vec1,vec2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now processing the matrix composed of those two stacked vectors:\n",
    "euclidean_distances(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe the differences with cosine similarity:\n",
    "cosine_similarity([vec1,vec2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity(matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Real Data\n",
    "\n",
    "We are going to look at and use a very well known dataset in machine learning from Ronald A. Fisher, “The Use of Multiple Measurements in Taxonomic Problems,” *Annals of Eugenics* 7, no. 2 (1936): 179–88. This dataset contains measurements of 150 Iris flowers, fifty samples each from three different kinds (classes, in the language of machine learning) using four measurements:\n",
    "   1. sepal length in cm\n",
    "   2. sepal width in cm\n",
    "   3. petal length in cm\n",
    "   4. petal width in cm\n",
    "\n",
    "What are these measurements or features? Why these?\n",
    "\n",
    "![Museum of Natural History](../img/parts-of-a-flower_full_amnh.png)\n",
    "\n",
    "\"Parts of a Flower,\" American Museum of Natural History\n",
    "https://www.amnh.org/learn-teach/curriculum-collections/biodiversity-counts/plant-identification/plant-morphology/parts-of-a-flower\n",
    "\n",
    "The three classes represented in the Fisher Iris dataset are: \n",
    "1. Iris Setosa\n",
    "2. Iris Versicolour\n",
    "3. Iris Virginica\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a local copy of the dataset and we'll read with a Python\n",
    "# package called Pandas, assigining short names to each of the columns\n",
    "# that represent the four features.\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../data/iris.data',names=[\"sl\",\"sw\",\"pl\",\"pw\",\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the class name for now and make into a matrix\n",
    "matrix = torch.tensor(df.iloc[:, : 4].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean values?\n",
    "matrix.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation?\n",
    "matrix.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset curators tell us a little more about the dataset here:\n",
    "\n",
    "8. Missing Attribute Values: None\n",
    "<pre>\n",
    "Summary Statistics:\n",
    "                 Min  Max   Mean    SD   Class Correlation\n",
    "   sepal length: 4.3  7.9   5.84  0.83    0.7826   \n",
    "    sepal width: 2.0  4.4   3.05  0.43   -0.4194\n",
    "   petal length: 1.0  6.9   3.76  1.76    0.9490  (high!)\n",
    "    petal width: 0.1  2.5   1.20  0.76    0.9565  (high!)\n",
    "</pre>\n",
    "\n",
    "9. Class Distribution: 33.3% for each of 3 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets look at the distance matrix. How does this look?\n",
    "euclidean_distances(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But there are better ways to view this!\n",
    "\n",
    "# assign dist variable to our distance matrix\n",
    "dist = euclidean_distances(matrix)\n",
    "\n",
    "# import what we need to visualize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# show it!\n",
    "plt.imshow(dist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll create a cosine DISimilarity plot by subtracting from 1\n",
    "# (making similarity items closer to 0 rather than 1)\n",
    "\n",
    "dist = 1 - cosine_similarity(matrix)\n",
    "\n",
    "# show it!\n",
    "plt.imshow(dist)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
