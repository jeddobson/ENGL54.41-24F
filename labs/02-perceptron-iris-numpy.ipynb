{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fe040f3-bf56-40d1-85a4-4492ab9f953c",
   "metadata": {},
   "source": [
    "# <center>Critical AI</center>\n",
    "<center>ENGL 54.41</center>\n",
    "<center>Dartmouth College</center>\n",
    "<center>Fall 2024</center>\n",
    "\n",
    "<pre>Created: 07/28/2021; Revised: 09/25/2024</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9733ae-05c7-443b-928f-c230efb2ec47",
   "metadata": {},
   "source": [
    "## The Perceptron: Simple Version in NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803b42eb-cf68-4249-bc13-965169c67046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dc2e88-26b0-435a-bd18-a282ef0d36d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a local copy of the dataset and we'll read with a Python\n",
    "# package called Pandas, assigining short names to each of the columns\n",
    "# that represent the four features.\n",
    "\n",
    "df = pd.read_csv('../data/iris.data',names=[\"sl\",\"sw\",\"pl\",\"pw\",\"class\"])                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ee2718-6aa9-4a7b-90a9-f39d426649a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first 100 samples are Iris-setosa and Iris-versicolor (50 of each)\n",
    "y = df.iloc[0:100, 4].values             # y is the typical variable name for labels in machine learning\n",
    "y = np.where(y == 'Iris-setosa', 0, 1)   # Here we are setting Iris-setosa to class 0 and Iris-versicolor to class 1\n",
    "X = df.iloc[0:100, [0,1,2,3]].values     # X is the typical variable name for data in machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a00c9e8-cd08-4a61-adff-c23244349972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a visualization of just the first two dimensions of the dataset\n",
    "# the gray dots are sepal length and sepal width for Iris-setosa and\n",
    "# the black dots are the same for Iris-versicolor. These are plotted as\n",
    "# x/y coordinates. Can you see a clear line separating these representations\n",
    "# using these two features? \n",
    "\n",
    "plt.scatter(X[:,0], X[:,1],c=np.where(y == 0, \"gray\",\"black\"))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e58dc1-ae4b-409f-bb25-c465512341df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of training iterations\n",
    "epochs = 10   # how many iterations should we use? What's a reasonable number? How do we know?\n",
    "\n",
    "# learning rate \n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbacf2d-a793-4db3-aa47-5ae3f0edb527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a set of weights dynamically from data (number of samples + 1)\n",
    "# the additional weight is known as the bias term\n",
    "weights = X.shape[1]\n",
    "weights = np.zeros(weights + 1)\n",
    "\n",
    "# these are simple weights for layer\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b0bfd4-40fd-4825-88a9-c042ba244ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a simple way to view a random sample of the training data\n",
    "import random\n",
    "random.choices(X,k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dbcbc5-f442-45dc-b4c0-00173221893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll create a prediction function that will return class 0 or 1\n",
    "# depending on the sum of activations\n",
    "\n",
    "def predict(input_data):\n",
    "    input_data = np.array(input_data)\n",
    "    \n",
    "    # in some versions of the Perceptron algorithm, this is done prior to prediction\n",
    "    weight_sum = np.dot(input_data, weights[1:]) + weights[0]\n",
    "\n",
    "    # sort of self-explanatory: return class based on sums\n",
    "    if weight_sum > 0:\n",
    "        activation = 1\n",
    "    else:\n",
    "        activation = 0\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9203c202-a711-42d5-8fa1-a2e54a8760e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the Perceptron on training data for both classes\n",
    "# and supply labels (either 0 or 1)\n",
    "\n",
    "# iterate through each of the training epochs\n",
    "for e in range(epochs):\n",
    "    # on each epoch, we update the weights with all the training data and labels\n",
    "    for inputs, label in zip(X, y):\n",
    "        # predict class and update weights\n",
    "        prediction = predict(inputs)\n",
    "        weights[1:] += learning_rate * (label - prediction) * inputs\n",
    "        weights[0] += learning_rate * (label - prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f829a76-055f-440c-9afe-6d086ca5ccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these weights define the hyperplane learned by the Perceptron\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2877f281-6050-4c9e-b963-bdafc452b671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample imaginary data (class 1 or Iris-versicolor)\n",
    "predict([6.8, 3.1, 4.5, 1.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aee8d2-c3bc-415a-9010-ae81230495d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample imaginary data (class 0 or Iris-setosa)\n",
    "predict([4.7, 3.0, 1.6, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19155152-21dd-4cda-983d-e696ba50b7aa",
   "metadata": {},
   "source": [
    "## Try it!\n",
    "Now try some of your own by inventing data that might belong to either class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0d0b9f-6297-4b05-9f5c-3d6e5c758600",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
