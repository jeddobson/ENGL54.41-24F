{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdd35e19-1601-4fec-bfcb-6b0540d52050",
   "metadata": {},
   "source": [
    "# <center>Critical AI</center>\n",
    "<center>ENGL 54.41</center>\n",
    "<center>Dartmouth College</center>\n",
    "<center>Fall 2024</center>\n",
    "<pre>Created: 10/03/2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7668b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "from glob import glob\n",
    "import cv2\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5d50f5-f420-4db0-8d2d-92cbeb6dd9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell of code will determine if we have an accelerator for running\n",
    "# our neural networks.\n",
    "# mps == Apple Silicon device (MX series of Macbooks)\n",
    "# cuda == Compute Unified Device Architecture is a toolkit from Nvidia and means we have a GPU\n",
    "# cpu == Just using the general-purpose CPU for our calculations\n",
    "\n",
    "if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('Using device: {0}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7957b8f0-6c24-4526-bbcd-ff4243d54a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are loading a transformer neural network (more on this architecture later this term)\n",
    "# there are three components that we need: the model, the image processor, and the tokenizer\n",
    "# we'll learn more about tokenization later, for now just know that this \n",
    "\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\",\n",
    "                                  torch_dtype=torch.float16,\n",
    "                                  device_map=\"auto\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\",\n",
    "                                          torch_dtype=torch.float16,\n",
    "                                          clean_up_tokenization_spaces=True,\n",
    "                                          device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f726b9-7213-4d88-ac37-a7def877a97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "!wget http://jeddobson.github.io/data/wheelock-succession.tgz\n",
    "!tar -zxf wheelock-succession.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b194c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the official portraits of Dartmouth College presidents \n",
    "# (the series of presidents is known as the \"Wheelock Succession\").\n",
    "wheelock_data = list()\n",
    "wheelock_succession = glob('wheelock-succession/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a7f6b9-c1e9-4666-aeb5-9cf21ded119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the official portraits\n",
    "fig = plt.figure(figsize=(10, 10))  # width, height in inches\n",
    "plt.title(\"The Wheelock Succession (Unordered)\")\n",
    "for i,idx in enumerate(wheelock_succession):\n",
    "    img = fig.add_subplot(4, 5, i + 1)\n",
    "    port = cv2.imread(wheelock_succession[i])\n",
    "    port = cv2.cvtColor(port, cv2.COLOR_BGR2RGB)\n",
    "    img.imshow(port)\n",
    "    img.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890028ac-471d-4066-b5d8-a1409d8ee09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will load these images and batch process them with CLIP\n",
    "# We'll just use a placeholder label (\"president\") to obtain\n",
    "# a representation of the image from the CLIP neural network.\n",
    "data = [Image.open(img) for img in wheelock_succession]\n",
    "inputs = processor(text=[\"president\"] * len(wheelock_succession), images=data, return_tensors=\"pt\", padding=True)\n",
    "outputs = model(**inputs.to(device))\n",
    "wheelock_data = outputs['image_embeds'].to('cpu').detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43535fef-16fb-4b1f-8f22-139358a16a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Cosine Similarity\n",
    "dist_matrix = cosine_similarity(wheelock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0fb809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the distances as cosine similarity. In this cell, we will take\n",
    "# the index of 0 for the first image shown above and sort the distances\n",
    "# to find, in order (well reverse order), the most similar representations\n",
    "# of these images. What do you notice?\n",
    "\n",
    "for i, idx in enumerate(np.argsort(dist_matrix[0])[::-1]):\n",
    "    print(dist_matrix[0][idx])\n",
    "    img = cv2.imread(wheelock_succession[idx])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc17935-46a1-4d6e-a8d3-832824d98824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are going to use a technique called \n",
    "# Pricipal Components Analysis or PCA to locate\n",
    "# the two most meaningful components of the image\n",
    "# representations (we'll call these embeddings). These\n",
    "# two components will provide us with x and y axis data\n",
    "# that we can plot.\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "plot_data = pca.fit_transform(wheelock_data)\n",
    "xs, ys = plot_data[:, 0], plot_data[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a01bbd2-8501-4c4e-b458-3f96cd36b8d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now display these as a scatter plot:\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "plt.clf()\n",
    "plt.title(\"Wheelock Succession\")\n",
    "plt.style.use('ggplot')\n",
    "plt.scatter(xs, ys, marker = '^')\n",
    "for i, w in enumerate(wheelock_succession):\n",
    "    a = w.split('/')[1]\n",
    "    plt.annotate(a, xy = (xs[i], ys[i]), xytext = (3, 3),\n",
    "        textcoords = 'offset points', ha = 'left', va = 'top')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ee3f4e-6039-4dd6-b5eb-5d0255f5a639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
